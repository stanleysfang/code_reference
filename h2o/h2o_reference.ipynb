{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h2o\n",
    "from h2o.estimators import H2ORandomForestEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_suffix = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='/home/sfang/windows/gitlab/stanleysfang/code_reference/h2o/data/'\n",
    "model_path='/home/sfang/windows/gitlab/stanleysfang/code_reference/h2o/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_171\"; OpenJDK Runtime Environment (build 1.8.0_171-8u171-b11-0ubuntu0.16.04.1-b11); OpenJDK 64-Bit Server VM (build 25.171-b11, mixed mode)\n",
      "  Starting server from /home/sfang/anaconda3/envs/h2o/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmp7h5324ln\n",
      "  JVM stdout: /tmp/tmp7h5324ln/h2o_sfang_started_from_python.out\n",
      "  JVM stderr: /tmp/tmp7h5324ln/h2o_sfang_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Los_Angeles</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.30.1.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>25 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_sfang_i3k5te</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.535 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.6.5 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         02 secs\n",
       "H2O_cluster_timezone:       America/Los_Angeles\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.30.1.3\n",
       "H2O_cluster_version_age:    25 days\n",
       "H2O_cluster_name:           H2O_from_python_sfang_i3k5te\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.535 Gb\n",
       "H2O_cluster_total_cores:    4\n",
       "H2O_cluster_allowed_cores:  4\n",
       "H2O_cluster_status:         accepting new members, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.6.5 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataprep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\n",
    "    data_path + \"train.csv\",\n",
    "    header=0, names=['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'ParCh', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_re = re.compile('^.*, (.*?)\\\\..*$')\n",
    "train['Title'] = train['Name'].apply(lambda x: title_re.search(x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_title = ['Mr', 'Mrs', 'Dr', 'Rev', 'Col', 'Major', 'Sir', 'Don', 'Dona', 'Mme', 'Jonkheer', 'Lady', 'Capt', 'the Countess']\n",
    "\n",
    "train.loc[train['Title'].isin(adult_title) & (train['Sex'] == 'male'), 'Title_cleaned'] = 'Mr'\n",
    "train.loc[train['Title'].isin(adult_title) & train['Sex'].isin(['female']), 'Title_cleaned'] = 'Mrs'\n",
    "train.loc[train['Title'].isin(['Miss', 'Ms', 'Mlle']), 'Title_cleaned'] = 'Miss'\n",
    "train.loc[train['Title'].isin(['Master']), 'Title_cleaned'] = 'Master'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_mean_age = train.loc[train['Title_cleaned'].isin(['Mr']), 'Age'].mean()\n",
    "mrs_mean_age = train.loc[train['Title_cleaned'].isin(['Mrs']), 'Age'].mean()\n",
    "miss_mean_age = train.loc[train['Title_cleaned'].isin(['Miss']), 'Age'].mean()\n",
    "master_mean_age = train.loc[train['Title_cleaned'].isin(['Master']), 'Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['Title_cleaned'].isin(['Mr']) & train['Age'].isna(), 'Age'] = mr_mean_age\n",
    "train.loc[train['Title_cleaned'].isin(['Mrs']) & train['Age'].isna(), 'Age'] = mrs_mean_age\n",
    "train.loc[train['Title_cleaned'].isin(['Miss']) & train['Age'].isna(), 'Age'] = miss_mean_age\n",
    "train.loc[train['Title_cleaned'].isin(['Master']) & train['Age'].isna(), 'Age'] = master_mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['Cabin'].isna(), 'Cabin'] = 'No Cabin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['Embarked'].isna(), 'Embarked'] = 'S'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\n",
    "    data_path + \"test.csv\",\n",
    "    header=0, names=['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'ParCh', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_re = re.compile('^.*, (.*?)\\\\..*$')\n",
    "test['Title'] = test['Name'].apply(lambda x: title_re.search(x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_title = ['Mr', 'Mrs', 'Dr', 'Rev', 'Col', 'Major', 'Sir', 'Don', 'Dona', 'Mme', 'Jonkheer', 'Lady', 'Capt', 'the Countess']\n",
    "\n",
    "test.loc[test['Title'].isin(adult_title) & (test['Sex'] == 'male'), 'Title_cleaned'] = 'Mr'\n",
    "test.loc[test['Title'].isin(adult_title) & test['Sex'].isin(['female']), 'Title_cleaned'] = 'Mrs'\n",
    "test.loc[test['Title'].isin(['Miss', 'Ms', 'Mlle']), 'Title_cleaned'] = 'Miss'\n",
    "test.loc[test['Title'] == 'Master', 'Title_cleaned'] = 'Master'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['Title_cleaned'].isin(['Mr']) & test['Age'].isna(), 'Age'] = mr_mean_age\n",
    "test.loc[test['Title_cleaned'].isin(['Mrs']) & test['Age'].isna(), 'Age'] = mrs_mean_age\n",
    "test.loc[test['Title_cleaned'].isin(['Miss']) & test['Age'].isna(), 'Age'] = miss_mean_age\n",
    "test.loc[test['Title_cleaned'].isin(['Master']) & test['Age'].isna(), 'Age'] = master_mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['Cabin'].isna(), 'Cabin'] = 'No Cabin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['Fare'].isna(), 'Fare'] = train.loc[train['Pclass'] == 3, 'Fare'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = pd.read_csv(\n",
    "    data_path + \"answers.csv\",\n",
    "    header=0, names=['PassengerId', 'Survived'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target/Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Survived'\n",
    "feature_cols = ['Pclass', 'Sex', 'Age', 'SibSp', 'ParCh', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Title_cleaned']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas dataframe to H2OFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train_h2o = h2o.H2OFrame(train, destination_frame='train', column_types={'Survived': 'enum', 'Pclass': 'enum', 'Name': 'enum', 'Sex': 'enum', 'Ticket': 'enum', 'Cabin': 'enum', 'Embarked': 'enum', 'Title': 'enum', 'Title_cleaned': 'enum'})\n",
    "test_h2o = h2o.H2OFrame(test, destination_frame='test', column_types={'Pclass': 'enum', 'Name': 'enum', 'Sex': 'enum', 'Ticket': 'enum', 'Cabin': 'enum', 'Embarked': 'enum', 'Title': 'enum', 'Title_cleaned': 'enum'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_id = 'my_model_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = H2ORandomForestEstimator(\n",
    "    model_id=rf_model_id,\n",
    "    nfolds=5,\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "rf_model.train(x=feature_cols, y=target, training_frame=train_h2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/Load H2O Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/Users/Stanley Fang/Documents/sfang/gitlab/stanleysfang/code_reference/h2o/models/my_model_0'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o.save_model(model=rf_model, path=model_path, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = model_path + 'my_model_0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid_id = 'rf_grid_' + time_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = H2OGridSearch(\n",
    "    H2ORandomForestEstimator(\n",
    "        ntrees=10000,\n",
    "        nfolds=5,\n",
    "        stopping_metric='AUC',\n",
    "        stopping_tolerance=1e-4,\n",
    "        stopping_rounds=3,\n",
    "        score_tree_interval=5,\n",
    "        seed=seed\n",
    "    ),\n",
    "    grid_id=rf_grid_id,\n",
    "    hyper_params={\n",
    "        'max_depth': [15, 20, 25],\n",
    "        'col_sample_rate_per_tree': [0.5, 0.7],\n",
    "        'mtries': [3, 5]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Grid Build progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "rf_grid.train(x=feature_cols, y=target, training_frame=train_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     col_sample_rate_per_tree max_depth mtries  \\\n",
      "0                         0.7        15      3   \n",
      "1                         0.7        25      3   \n",
      "2                         0.7        20      3   \n",
      "3                         0.5        25      3   \n",
      "4                         0.5        20      3   \n",
      "5                         0.5        15      3   \n",
      "6                         0.5        15      5   \n",
      "7                         0.5        20      5   \n",
      "8                         0.5        25      5   \n",
      "9                         0.7        25      5   \n",
      "10                        0.7        20      5   \n",
      "11                        0.7        15      5   \n",
      "\n",
      "                           model_ids                 auc  \n",
      "0    rf_grid_20201023_214548_model_2  0.8795657175726201  \n",
      "1    rf_grid_20201023_214548_model_6  0.8788280659146348  \n",
      "2    rf_grid_20201023_214548_model_4  0.8782049233587916  \n",
      "3    rf_grid_20201023_214548_model_5  0.8752649687363521  \n",
      "4    rf_grid_20201023_214548_model_3  0.8749800274821845  \n",
      "5    rf_grid_20201023_214548_model_1  0.8745326430831176  \n",
      "6    rf_grid_20201023_214548_model_7  0.8584720757570916  \n",
      "7    rf_grid_20201023_214548_model_9  0.8565760180658082  \n",
      "8   rf_grid_20201023_214548_model_11   0.856381618892404  \n",
      "9   rf_grid_20201023_214548_model_12  0.8499424791486914  \n",
      "10  rf_grid_20201023_214548_model_10  0.8497480799752873  \n",
      "11   rf_grid_20201023_214548_model_8  0.8484272307970898  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_grid_auc = rf_grid.get_grid(sort_by='auc', decreasing=True)\n",
    "print(rf_grid_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving/Loading Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sfang/windows/gitlab/stanleysfang/code_reference/h2o/models/rf_grid_20201023_214548/rf_grid_20201023_214548'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o.save_grid(model_path + rf_grid_auc.grid_id, rf_grid_auc.grid_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = h2o.load_grid(model_path + 'rf_grid_20201023_172627/rf_grid_20201023_172627')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sfang/anaconda3/envs/h2o/lib/python3.6/site-packages/h2o/job.py:70: UserWarning: Test/Validation dataset column 'Ticket' has levels not trained on: [110469, 110489, 111163, 112051, 112377, 112378, 112901, 113038, 113044, 113054, 113778, 113780, 113790, 113791, 113795, 113801, 11770, 11778, 1222, 13050, 13236, 13508, 13695, 13905, 17475, 17765, 17770, 19924, 211535, 21228, 21332, 220844, 233478, 233734, 235509, 236854, 237216, 237249, 237393, 237670, 237734, 237735, 239059, 240261, 240276, 24065, 242963, 244346, 244360, 244368, 248659, 248726, 248734, 248744, 248746, 250650, 2543, 2621, 2622, 2652, 2654, 2655, 2656, 2657, 2658, 2660, 2670, 2673, 2675, 2676, 2679, 2681, 2682, 2684, 2688, 2692, 2696, 2698, 28004, 28034, 28133, 28221, 28404, 28666, 29107, 3101266, 3101297, 315083, 315085, 315087, 315091, 315092, 315095, 315152, 315154, 32302, 329944, 330844, 330910, 330911, 330920, 330924, 330963, 330968, 330971, 330972, 334914, 334915, 335432, 3410, 342441, 342684, 342712, 343271, 345498, 345501, 345768, 345771, 345775, 3470, 347065, 347066, 347070, 347072, 347075, 347079, 347086, 347090, 347091, 347465, 347467, 347469, 347471, 348122, 348125, 349202, 349211, 349220, 349226, 349229, 349230, 349232, 349235, 349238, 349250, 349255, 349911, 350033, 350045, 350053, 350054, 350403, 350405, 350408, 350409, 350410, 350416, 359306, 359309, 363272, 363611, 364856, 364858, 364859, 365235, 365237, 366713, 367227, 368364, 368402, 368573, 368702, 368783, 3701, 370368, 370374, 371109, 376563, 382650, 382653, 383123, 383162, 392095, 65305, 680, 694, 7266, 7538, 7548, 7935, 9232, A. 2. 39186, A./5. 3338, A.5. 3236, A/4 31416, A/4 48873, A/5 1478, A/5 21175, AQ/3. 30631, AQ/4 3130, C 17368, C.A. 15185, C.A. 30769, C.A. 31029, C.A. 31030, C.A. 34050, C.A. 34644, C.A. 42795, C.A. 49867, CA 31352, F.C. 12998, F.C.C. 13534, F.C.C. 13540, LP 1588, PC 17531, PC 17562, PC 17580, PC 17591, PC 17594, PC 17598, PC 17606, PC 17607, PC 17613, S.O./P.P. 2, S.O./P.P. 251, S.O./P.P. 752, SC 14888, SC/A.3 2861, SC/A4 23568, SC/PARIS 2147, SC/PARIS 2148, SC/PARIS 2159, SC/PARIS 2166, SC/PARIS 2168, SOTON/O.Q. 3101262, SOTON/O.Q. 3101263, SOTON/O.Q. 3101308, SOTON/O.Q. 3101309, SOTON/O.Q. 3101314, SOTON/O.Q. 3101315, SOTON/O2 3101284, SOTON/OQ 392083, STON/O 2. 3101268, STON/O 2. 3101291, STON/O2. 3101270, STON/OQ. 369943, W./C. 14260, W./C. 14266]\n",
      "  warnings.warn(w)\n",
      "/home/sfang/anaconda3/envs/h2o/lib/python3.6/site-packages/h2o/job.py:70: UserWarning: Test/Validation dataset column 'Cabin' has levels not trained on: [A11, A18, A21, A29, A9, B10, B11, B24, B26, B36, B45, B52 B54 B56, B61, C105, C116, C130, C132, C28, C31, C39, C51, C53, C55 C57, C6, C80, C89, C97, D22, D34, D38, D40, D43, E39 E41, E45, E52, E60, F, F E46, F E57]\n",
      "  warnings.warn(w)\n"
     ]
    }
   ],
   "source": [
    "model = rf_grid_auc.models[0]\n",
    "predict = model.predict(test_h2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H2OFrame to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8038277511961722"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(answers['Survived'] == predict.as_data_frame()['predict']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shutting Down H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_9bbb closed.\n"
     ]
    }
   ],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 (h2o)",
   "language": "python",
   "name": "h2o"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
